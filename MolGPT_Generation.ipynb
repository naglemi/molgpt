{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤  MolGPT Generation - Cowboy Chronicle ðŸ¤ \n",
    "\n",
    "This notebook demonstrates how to use the trained MolGPT model to generate novel molecules, either unconditionally or with property/scaffold conditioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "First, let's make sure we have all the necessary imports and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import json\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import Crippen\n",
    "from rdkit.Chem.Descriptors import ExactMolWt\n",
    "from rdkit.Chem.rdMolDescriptors import CalcTPSA\n",
    "\n",
    "# Import directly from the files instead of using package imports\n",
    "sys.path.insert(0, '.')\n",
    "from train.model import GPT, GPTConfig\n",
    "from generate.utils import sample, check_novelty, canonic_smiles\n",
    "from moses.utils import get_mol\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset and Vocabulary\n",
    "\n",
    "Let's load the dataset and vocabulary for tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Moses dataset\n",
    "data_name = 'moses2'\n",
    "data = pd.read_csv(f'datasets/{data_name}.csv')\n",
    "data = data.dropna(axis=0).reset_index(drop=True)\n",
    "data.columns = data.columns.str.lower()\n",
    "\n",
    "# Display the first few rows\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regex pattern for tokenizing SMILES\n",
    "pattern = \"(\\[[^\\]]+]|<|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "regex = re.compile(pattern)\n",
    "\n",
    "# Define the character set\n",
    "whole_string = ['#', '%10', '%11', '%12', '(', ')', '-', '1', '2', '3', '4', '5', '6', '7', '8', '9', '<', '=', 'B', 'Br', 'C', 'Cl', 'F', 'I', 'N', 'O', 'P', 'S', '[B-]', '[BH-]', '[BH2-]', '[BH3-]', '[B]', '[C+]', '[C-]', '[CH+]', '[CH-]', '[CH2+]', '[CH2]', '[CH]', '[F+]', '[H]', '[I+]', '[IH2]', '[IH]', '[N+]', '[N-]', '[NH+]', '[NH-]', '[NH2+]', '[NH3+]', '[N]', '[O+]', '[O-]', '[OH+]', '[O]', '[P+]', '[PH+]', '[PH2+]', '[PH]', '[S+]', '[S-]', '[SH+]', '[SH]', '[Se+]', '[SeH+]', '[SeH]', '[Se]', '[Si-]', '[SiH-]', '[SiH2]', '[SiH]', '[Si]', '[b-]', '[bH-]', '[c+]', '[c-]', '[cH+]', '[cH-]', '[n+]', '[n-]', '[nH+]', '[nH]', '[o+]', '[s+]', '[sH+]', '[se+]', '[se]', 'b', 'c', 'n', 'o', 'p', 's']\n",
    "\n",
    "# Create vocabulary mappings\n",
    "stoi = {ch: i for i, ch in enumerate(whole_string)}\n",
    "itos = {i: ch for i, ch in enumerate(whole_string)}\n",
    "\n",
    "# Save vocabulary mappings to JSON files\n",
    "with open(f'{data_name}_stoi.json', 'w') as f:\n",
    "    json.dump(stoi, f)\n",
    "\n",
    "print(f\"Vocabulary size: {len(stoi)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Pre-trained Model\n",
    "\n",
    "Now we'll load a pre-trained model for molecule generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "vocab_size = len(stoi)\n",
    "block_size = 54  # Maximum SMILES length\n",
    "n_layer = 8\n",
    "n_head = 8\n",
    "n_embd = 256\n",
    "scaffold_max_len = 48  # For Moses dataset\n",
    "\n",
    "# Choose the model type\n",
    "model_type = \"qed\"  # Options: qed, sas, logp, tpsa\n",
    "model_weight = f\"/home/ubuntu/molgpt/datasets/weights/moses_scaf_wholeseq_{model_type}.pt\"\n",
    "\n",
    "# Define model configuration\n",
    "mconf = GPTConfig(vocab_size, block_size, \n",
    "                  num_props=1,  # Using 1 property for conditioning\n",
    "                  n_layer=n_layer, n_head=n_head, n_embd=n_embd, \n",
    "                  scaffold=True, scaffold_maxlen=scaffold_max_len,\n",
    "                  lstm=False, lstm_layers=0)\n",
    "\n",
    "# Create the model\n",
    "model = GPT(mconf)\n",
    "\n",
    "# Load pre-trained weights\n",
    "model.load_state_dict(torch.load(model_weight, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded from {model_weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Unconditional Molecule Generation\n",
    "\n",
    "Let's start with unconditional molecule generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set generation parameters\n",
    "context = \"C\"  # Starting with a carbon atom\n",
    "batch_size = 5  # Generate 5 molecules at once\n",
    "temperature = 1.0  # Temperature for sampling (higher = more diverse)\n",
    "top_k = None  # No top-k sampling\n",
    "\n",
    "# Tokenize the context\n",
    "x = torch.tensor([stoi[s] for s in regex.findall(context)], dtype=torch.long)[None,...].repeat(batch_size, 1).to(device)\n",
    "\n",
    "# Generate molecules\n",
    "with torch.no_grad():\n",
    "    y = sample(model, x, block_size, temperature=temperature, sample=True, top_k=top_k, prop=None, scaffold=None)\n",
    "\n",
    "# Convert generated tokens to SMILES strings\n",
    "generated_smiles = []\n",
    "for gen_mol in y:\n",
    "    completion = ''.join([itos[int(i)] for i in gen_mol])\n",
    "    completion = completion.replace('<', '')  # Remove padding tokens\n",
    "    generated_smiles.append(completion)\n",
    "\n",
    "# Convert SMILES to molecules\n",
    "molecules = []\n",
    "valid_smiles = []\n",
    "for smiles in generated_smiles:\n",
    "    mol = get_mol(smiles)\n",
    "    if mol:\n",
    "        molecules.append(mol)\n",
    "        valid_smiles.append(Chem.MolToSmiles(mol))\n",
    "\n",
    "# Display results\n",
    "print(f\"Generated {len(generated_smiles)} molecules, {len(molecules)} are valid.\")\n",
    "print(\"\\nGenerated SMILES:\")\n",
    "for i, smiles in enumerate(valid_smiles):\n",
    "    print(f\"{i+1}. {smiles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the generated molecules\n",
    "if molecules:\n",
    "    img = Draw.MolsToGridImage(molecules, molsPerRow=3, subImgSize=(300, 300), legends=[f\"Mol {i+1}\" for i in range(len(molecules))])\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Property-Conditioned Generation\n",
    "\n",
    "Now let's generate molecules conditioned on specific property values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set property conditioning values\n",
    "if model_type == \"qed\":\n",
    "    prop_values = [0.6, 0.75, 0.9]  # QED values (drug-likeness)\n",
    "elif model_type == \"logp\":\n",
    "    prop_values = [1.0, 2.0, 3.0]  # LogP values (lipophilicity)\n",
    "elif model_type == \"sas\":\n",
    "    prop_values = [2.0, 3.0, 4.0]  # SAS values (synthetic accessibility)\n",
    "elif model_type == \"tpsa\":\n",
    "    prop_values = [40.0, 80.0, 120.0]  # TPSA values (polar surface area)\n",
    "else:\n",
    "    prop_values = [0.75]  # Default\n",
    "\n",
    "# Generate molecules for each property value\n",
    "all_molecules = []\n",
    "all_smiles = []\n",
    "all_props = []\n",
    "\n",
    "for prop_value in prop_values:\n",
    "    print(f\"\\nGenerating molecules with {model_type} = {prop_value}\")\n",
    "    \n",
    "    # Tokenize the context\n",
    "    x = torch.tensor([stoi[s] for s in regex.findall(context)], dtype=torch.long)[None,...].repeat(batch_size, 1).to(device)\n",
    "    \n",
    "    # Set property conditioning\n",
    "    p = torch.tensor([[prop_value]]).repeat(batch_size, 1).to(device)\n",
    "    \n",
    "    # Generate molecules\n",
    "    with torch.no_grad():\n",
    "        y = sample(model, x, block_size, temperature=temperature, sample=True, top_k=top_k, prop=p, scaffold=None)\n",
    "    \n",
    "    # Convert generated tokens to SMILES strings\n",
    "    generated_smiles = []\n",
    "    for gen_mol in y:\n",
    "        completion = ''.join([itos[int(i)] for i in gen_mol])\n",
    "        completion = completion.replace('<', '')  # Remove padding tokens\n",
    "        generated_smiles.append(completion)\n",
    "    \n",
    "    # Convert SMILES to molecules\n",
    "    molecules = []\n",
    "    valid_smiles = []\n",
    "    for smiles in generated_smiles:\n",
    "        mol = get_mol(smiles)\n",
    "        if mol:\n",
    "            molecules.append(mol)\n",
    "            valid_smiles.append(Chem.MolToSmiles(mol))\n",
    "    \n",
    "    # Store results\n",
    "    all_molecules.extend(molecules)\n",
    "    all_smiles.extend(valid_smiles)\n",
    "    all_props.extend([prop_value] * len(molecules))\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"Generated {len(generated_smiles)} molecules, {len(molecules)} are valid.\")\n",
    "    for i, smiles in enumerate(valid_smiles[:3]):  # Show only first 3\n",
    "        print(f\"{i+1}. {smiles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the property-conditioned molecules\n",
    "if all_molecules:\n",
    "    # Show only up to 9 molecules\n",
    "    display_mols = all_molecules[:min(9, len(all_molecules))]\n",
    "    display_props = all_props[:min(9, len(all_molecules))]\n",
    "    \n",
    "    img = Draw.MolsToGridImage(display_mols, molsPerRow=3, subImgSize=(300, 300), \n",
    "                              legends=[f\"{model_type}={p}\" for p in display_props])\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Scaffold-Conditioned Generation\n",
    "\n",
    "Now let's generate molecules conditioned on specific scaffolds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scaffold conditions\n",
    "scaffolds = [\n",
    "    'c1ccccc1',  # Benzene\n",
    "    'c1ccncc1',  # Pyridine\n",
    "    'c1ccccc1N'  # Aniline\n",
    "]\n",
    "\n",
    "# Generate molecules for each scaffold\n",
    "all_scaffold_molecules = []\n",
    "all_scaffold_smiles = []\n",
    "all_scaffold_conditions = []\n",
    "\n",
    "for scaffold in scaffolds:\n",
    "    print(f\"\\nGenerating molecules with scaffold: {scaffold}\")\n",
    "    \n",
    "    # Tokenize the context\n",
    "    x = torch.tensor([stoi[s] for s in regex.findall(context)], dtype=torch.long)[None,...].repeat(batch_size, 1).to(device)\n",
    "    \n",
    "    # Pad the scaffold\n",
    "    padded_scaffold = scaffold + '<' * (scaffold_max_len - len(regex.findall(scaffold)))\n",
    "    \n",
    "    # Tokenize the scaffold\n",
    "    sca = torch.tensor([stoi[s] for s in regex.findall(padded_scaffold)], dtype=torch.long)[None,...].repeat(batch_size, 1).to(device)\n",
    "    \n",
    "    # Generate molecules\n",
    "    with torch.no_grad():\n",
    "        y = sample(model, x, block_size, temperature=temperature, sample=True, top_k=top_k, prop=None, scaffold=sca)\n",
    "    \n",
    "    # Convert generated tokens to SMILES strings\n",
    "    generated_smiles = []\n",
    "    for gen_mol in y:\n",
    "        completion = ''.join([itos[int(i)] for i in gen_mol])\n",
    "        completion = completion.replace('<', '')  # Remove padding tokens\n",
    "        generated_smiles.append(completion)\n",
    "    \n",
    "    # Convert SMILES to molecules\n",
    "    molecules = []\n",
    "    valid_smiles = []\n",
    "    for smiles in generated_smiles:\n",
    "        mol = get_mol(smiles)\n",
    "        if mol:\n",
    "            molecules.append(mol)\n",
    "            valid_smiles.append(Chem.MolToSmiles(mol))\n",
    "    \n",
    "    # Store results\n",
    "    all_scaffold_molecules.extend(molecules)\n",
    "    all_scaffold_smiles.extend(valid_smiles)\n",
    "    all_scaffold_conditions.extend([scaffold] * len(molecules))\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"Generated {len(generated_smiles)} molecules, {len(molecules)} are valid.\")\n",
    "    for i, smiles in enumerate(valid_smiles[:3]):  # Show only first 3\n",
    "        print(f\"{i+1}. {smiles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the scaffold-conditioned molecules\n",
    "if all_scaffold_molecules:\n",
    "    # Show only up to 9 molecules\n",
    "    display_mols = all_scaffold_molecules[:min(9, len(all_scaffold_molecules))]\n",
    "    display_scaffolds = all_scaffold_conditions[:min(9, len(all_scaffold_molecules))]\n",
    "    \n",
    "    img = Draw.MolsToGridImage(display_mols, molsPerRow=3, subImgSize=(300, 300), \n",
    "                              legends=[f\"Scaffold: {s}\" for s in display_scaffolds])\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "In this notebook, we've demonstrated how to use MolGPT for molecular generation with different conditioning strategies:\n",
    "\n",
    "1. **Unconditional Generation**: Generate molecules without any constraints\n",
    "2. **Property-Conditioned Generation**: Generate molecules with specific property values (QED, LogP, SAS, TPSA)\n",
    "3. **Scaffold-Conditioned Generation**: Generate molecules containing specific molecular scaffolds\n",
    "\n",
    "The MolGPT model provides a powerful and flexible approach to molecular generation, allowing for precise control over the generated structures through various conditioning mechanisms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (molgpt)",
   "language": "python",
   "name": "molgpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
